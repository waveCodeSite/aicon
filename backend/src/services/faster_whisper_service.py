import os
import json
from faster_whisper import WhisperModel
from opencc import OpenCC
from src.core.logging import get_logger

logger = get_logger(__name__)


class WhisperTranscriptionService:
    def __init__(self, model_size="small", device="cpu", compute_type="float32"):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆå¯å¤ç”¨æ¨¡å‹ï¼Œä¸éœ€è¦æ¯æ¬¡éƒ½åŠ è½½ï¼‰
        """
        logger.info(f"ğŸ”„ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {model_size} ...")
        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)
        self.cc = OpenCC('t2s')  # ç¹â†’ç®€è½¬æ¢
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    @staticmethod
    def format_timestamp(seconds: float):
        milliseconds = int((seconds % 1) * 1000)
        seconds = int(seconds)
        minutes = seconds // 60
        hours = minutes // 60
        minutes = minutes % 60
        seconds = seconds % 60
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

    def transcribe(self, audio_path, output_format="all"):
        """
        æ‰§è¡Œè¯­éŸ³è½¬å†™ä»»åŠ¡
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param output_format: json / srt / all
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")

        logger.info(f"ğŸš€ å¼€å§‹è¯†åˆ«éŸ³é¢‘: {audio_path}")

        segments, info = self.model.transcribe(
            audio_path,
            beam_size=10,
            vad_filter=True,
            word_timestamps=True,
            language="zh",
            task="transcribe",
            temperature=0.0,
        )

        logger.info(f"â„¹ï¸ æ£€æµ‹è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.2f})")

        results = []
        srt_content = ""

        for i, segment in enumerate(segments, start=1):

            # è½¬æˆç®€ä½“
            text_simplified = self.cc.convert(segment.text.strip())
            logger.info(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {text_simplified}")

            item = {
                "id": i,
                "start": segment.start,
                "end": segment.end,
                "text": text_simplified,
                "words": []
            }

            if segment.words:
                for w in segment.words:
                    item["words"].append({
                        "word": self.cc.convert(w.word),
                        "start": w.start,
                        "end": w.end
                    })

            results.append(item)

            # ç”Ÿæˆ SRT å­—å¹•å—
            srt_content += f"{i}\n"
            srt_content += f"{self.format_timestamp(segment.start)} --> {self.format_timestamp(segment.end)}\n"
            srt_content += f"{text_simplified}\n\n"

        base_name = os.path.splitext(audio_path)[0]

        # ä¿å­˜ JSON
        if output_format in ["json", "all"]:
            json_path = f"{base_name}.json"
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… JSON æ—¶é—´è½´å·²ä¿å­˜: {json_path}")

        # ä¿å­˜ SRT
        if output_format in ["srt", "all"]:
            srt_path = f"{base_name}.srt"
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt_content)
            logger.info(f"âœ… SRT å­—å¹•å·²ä¿å­˜: {srt_path}")

        return results, srt_content

transcription_service = WhisperTranscriptionService()

all = [
    "WhisperTranscriptionService",
    "transcription_service"
]


# -------------------------
# ä½¿ç”¨æ–¹å¼ç¤ºä¾‹
# -------------------------

if __name__ == "__main__":
    INPUT_FILE = "test.mp3"
    if not os.path.exists(INPUT_FILE):
        logger.info(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {INPUT_FILE}")
    else:
        transcription_service.transcribe(INPUT_FILE, output_format="all")
