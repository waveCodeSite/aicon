import os
import json
from src.core.logging import get_logger

logger = get_logger(__name__)

# è®¾ç½® HuggingFace ç¼“å­˜ç›®å½•
os.environ.setdefault("HF_HOME", "/tmp/huggingface")
os.environ.setdefault("TRANSFORMERS_CACHE", "/tmp/huggingface")


class WhisperTranscriptionService:
    def __init__(self, model_size="small", device="cpu", compute_type="float32"):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆå»¶è¿ŸåŠ è½½æ¨¡å‹ï¼‰
        """
        self._model = None
        self._cc = None
        self._model_size = model_size
        self._device = device
        self._compute_type = compute_type

    def _ensure_model_loaded(self):
        """ç¡®ä¿æ¨¡å‹å·²åŠ è½½"""
        if self._model is None:
            from faster_whisper import WhisperModel
            from opencc import OpenCC
            logger.info(f"æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {self._model_size} ...")
            self._model = WhisperModel(self._model_size, device=self._device, compute_type=self._compute_type)
            self._cc = OpenCC("t2s")
            logger.info("æ¨¡å‹åŠ è½½å®Œæˆ")

    @property
    def model(self):
        self._ensure_model_loaded()
        return self._model

    @property
    def cc(self):
        self._ensure_model_loaded()
        return self._cc

    @staticmethod
    def format_timestamp(seconds: float):
        milliseconds = int((seconds % 1) * 1000)
        seconds = int(seconds)
        minutes = seconds // 60
        hours = minutes // 60
        minutes = minutes % 60
        seconds = seconds % 60
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

    def transcribe(self, audio_path, output_format="all"):
        """
        æ‰§è¡Œè¯­éŸ³è½¬å†™ä»»åŠ¡
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param output_format: json / srt / all
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")

        logger.info(f"ğŸš€ å¼€å§‹è¯†åˆ«éŸ³é¢‘: {audio_path}")

        segments, info = self.model.transcribe(
            audio_path,
            beam_size=10,
            vad_filter=True,
            word_timestamps=True,
            language="zh",
            task="transcribe",
            temperature=0.0,
        )

        logger.info(
            f"â„¹ï¸ æ£€æµ‹è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.2f})"
        )

        results = []
        srt_content = ""

        for i, segment in enumerate(segments, start=1):

            # è½¬æˆç®€ä½“
            text_simplified = self.cc.convert(segment.text.strip())
            logger.info(
                f"[{segment.start:.2f}s -> {segment.end:.2f}s] {text_simplified}"
            )

            item = {
                "id": i,
                "start": segment.start,
                "end": segment.end,
                "text": text_simplified,
                "words": [],
            }

            if segment.words:
                for w in segment.words:
                    item["words"].append(
                        {
                            "word": self.cc.convert(w.word),
                            "start": w.start,
                            "end": w.end,
                        }
                    )

            results.append(item)

            # ç”Ÿæˆ SRT å­—å¹•å—
            srt_content += f"{i}\n"
            srt_content += f"{self.format_timestamp(segment.start)} --> {self.format_timestamp(segment.end)}\n"
            srt_content += f"{text_simplified}\n\n"

        base_name = os.path.splitext(audio_path)[0]

        # ä¿å­˜ JSON
        if output_format in ["json", "all"]:
            json_path = f"{base_name}.json"
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… JSON æ—¶é—´è½´å·²ä¿å­˜: {json_path}")

        # ä¿å­˜ SRT
        if output_format in ["srt", "all"]:
            srt_path = f"{base_name}.srt"
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt_content)
            logger.info(f"âœ… SRT å­—å¹•å·²ä¿å­˜: {srt_path}")

        return results, srt_content


transcription_service = WhisperTranscriptionService()

all = ["WhisperTranscriptionService", "transcription_service"]


# -------------------------
# ä½¿ç”¨æ–¹å¼ç¤ºä¾‹
# -------------------------

if __name__ == "__main__":
    INPUT_FILE = "test.mp3"
    if not os.path.exists(INPUT_FILE):
        logger.info(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {INPUT_FILE}")
    else:
        transcription_service.transcribe(INPUT_FILE, output_format="all")
